import AsyncStorage from "@react-native-async-storage/async-storage";
import * as tf from "@tensorflow/tfjs";
import "@tensorflow/tfjs-react-native";
import { parseAmountVN } from "../utils/textPreprocessing";
import { phobertExtractor } from "./phobertAmountExtractor";
import { transactionIntentClassifier } from "./transactionIntentClassifier";

interface Category {
  id: string;
  name: string;
  type: "income" | "expense";
  icon?: string | null;
  color?: string | null;
}

interface CategoryPrediction {
  categoryId: string;
  categoryName: string;
  confidence: number; // 0-100
}

interface ParsedTransaction {
  action:
    | "CREATE_TRANSACTION"
    | "VIEW_STATS"
    | "EDIT_TRANSACTION"
    | "DELETE_TRANSACTION";
  amount: number | null;
  note: string;
  categoryId: string;
  categoryName: string;
  io: "IN" | "OUT";
  date: Date;
  message: string;
  primary?: CategoryPrediction; // Primary prediction with confidence
  alternatives?: CategoryPrediction[]; // Alternative predictions (top 2-3)
  confidenceThreshold?: number; // Threshold for showing alternatives (default 75)
}

type AmountExtractionResult = {
  amount: number | null;
  confidence: number;
  tokens: string[];
  labels: string[];
};

class TensorFlowTransactionParser {
  private model: tf.LayersModel | null = null;
  private vocab: Map<string, number> = new Map();
  private maxSequenceLength: number = 50;
  private isInitialized: boolean = false;

  /**
   * Initialize TensorFlow and load/create model
   */
  async initialize(): Promise<void> {
    if (this.isInitialized) return;

    try {
      console.log("üîß Initializing TensorFlow...");

      // Kh·ªüi t·∫°o TensorFlow cho React Native
      await tf.ready();
      console.log("‚úÖ TensorFlow ready");

      // Th·ª≠ t·∫£i m√¥ h√¨nh ƒë√£ t·ªìn t·∫°i
      try {
        const modelJson = await AsyncStorage.getItem("tf_transaction_model");
        const vocabJson = await AsyncStorage.getItem("tf_vocab");

        if (modelJson && vocabJson) {
          // T·∫£i m√¥ h√¨nh t·ª´ b·ªô nh·ªõ
          const modelData = JSON.parse(modelJson);
          this.model = await tf.loadLayersModel(tf.io.fromMemory(modelData));
          this.vocab = new Map(JSON.parse(vocabJson));
          console.log("‚úÖ Loaded existing TF model from storage");
        } else {
          // T·∫°o m√¥ h√¨nh m·ªõi
          await this.createModel();
          console.log("‚úÖ Created new TF model");
        }
      } catch (error) {
        console.log("‚ö†Ô∏è No existing model, creating new one");
        await this.createModel();
      }

      this.isInitialized = true;
    } catch (error) {
      console.error("‚ùå TensorFlow initialization failed:", error);
      throw error;
    }
  }

  /**
   * T·∫°o m√¥ h√¨nh m·∫°ng n∆°-ron m·ªõi ƒë·ªÉ ph√¢n lo·∫°i vƒÉn b·∫£n
   */
  private async createModel(): Promise<void> {
    // M√¥ h√¨nh ph√¢n lo·∫°i vƒÉn b·∫£n ƒë∆°n gi·∫£n
    // ƒê·∫ßu v√†o: vƒÉn b·∫£n ƒë√£ token h√≥a ‚Üí Embedding ‚Üí LSTM ‚Üí Dense ‚Üí Output
    this.model = tf.sequential({
      layers: [
        tf.layers.embedding({
          inputDim: 5000, // vocabulary size
          outputDim: 128, // embedding dimension
          inputLength: this.maxSequenceLength,
        }),
        tf.layers.lstm({
          units: 64,
          returnSequences: false,
        }),
        tf.layers.dropout({ rate: 0.3 }),
        tf.layers.dense({
          units: 32,
          activation: "relu",
        }),
        tf.layers.dense({
          units: 10, // number of possible actions/categories
          activation: "softmax",
        }),
      ],
    });

    this.model.compile({
      optimizer: tf.train.adam(0.001),
      loss: "categoricalCrossentropy",
      metrics: ["accuracy"],
    });
  }

  /**
   * Ph√¢n t√≠ch vƒÉn b·∫£n giao d·ªãch c·ª•c b·ªô, kh√¥ng c·∫ßn API
   */
  async parseTransaction(
    text: string,
    userCategories: Category[]
  ): Promise<ParsedTransaction | null> {
    try {
      // AI-first local parsing (offline)

      // B∆∞·ªõc 1: Nh·∫≠n di·ªán lo·∫°i h√†nh ƒë·ªông (AI-first)
      const action = await this.detectActionTypeAI(text);
      console.log("üìã Action type:", action);

      // B∆∞·ªõc 2: Ph√¢n t√≠ch s·ªë ti·ªÅn (on-device sequence tagging; regex only as last fallback)
      const amountResult: AmountExtractionResult | null =
        action === "CREATE_TRANSACTION"
          ? await this.parseAmountHybrid(text)
          : null;
      const amount = amountResult?.amount ?? null;
      console.log("üí∞ Amount:", amount);

      // B∆∞·ªõc 3: Nh·∫≠n di·ªán lu·ªìng ti·ªÅn (keyword-based + defer to category model)
      const io = this.detectIOType(text);
      console.log("üìä IO type:", io);

      // B∆∞·ªõc 4: Ph√¢n t√≠ch ng√†y
      const date = this.parseDate(text);
      console.log("üìÖ Date:", date);

      // B∆∞·ªõc 5: Tr√≠ch ghi ch√∫ (lo·∫°i b·ªè span s·ªë ti·ªÅn b·∫±ng nh√£n t·ª´ model; tr√°nh regex)
      const note = this.extractNote(text, amountResult || undefined);
      console.log("üìù Note:", note);

      // B∆∞·ªõc 6: Danh m·ª•c s·∫Ω ƒë∆∞·ª£c ph√¢n lo·∫°i b·ªüi model l·ªãch s·ª≠ (transactionClassifier) ·ªü chatbox.
      const fallbackCategory =
        userCategories.find((c) => c.type === "expense") || userCategories[0];
      const primary: CategoryPrediction = {
        categoryId: fallbackCategory?.id || "",
        categoryName:
          fallbackCategory?.name || (io === "IN" ? "Thu nh·∫≠p" : "Chi ti√™u"),
        confidence: 10,
      };
      const alternatives: CategoryPrediction[] = [];

      // B∆∞·ªõc 7: T·∫°o th√¥ng ƒëi·ªáp
      const primaryCategory = userCategories.find(
        (c) => c.id === primary.categoryId
      );
      const message = this.generateMessage(
        action,
        amount,
        note,
        primaryCategory,
        date,
        primary.confidence
      );

      const confidenceThreshold = 75; // Show alternatives if confidence < 75%

      return {
        action,
        amount,
        note,
        categoryId: primary.categoryId,
        categoryName: primary.categoryName,
        io,
        date,
        message,
        primary,
        alternatives: alternatives.filter(
          (alt) => alt.confidence < confidenceThreshold && alt.confidence > 20 // Only show meaningful alternatives
        ),
        confidenceThreshold,
      };
    } catch (error) {
      console.error("‚ùå TensorFlow parsing failed:", error);
      return null;
    }
  }

  /**
   * AI-first detect action type (offline)
   */
  private async detectActionTypeAI(
    text: string
  ): Promise<ParsedTransaction["action"]> {
    try {
      const pred = await transactionIntentClassifier.predictAction(text);
      if (pred.confidence >= 0.6) return pred.action;
    } catch {
      // ignore
    }
    return "CREATE_TRANSACTION";
  }

  /**
   * Detect IO type (Income vs Expense) from text keywords
   */
  private detectIOType(text: string): "IN" | "OUT" {
    const lowerText = text.toLowerCase();

    // Income keywords (Vietnamese)
    const incomeKeywords = [
      "l∆∞∆°ng",
      "thu nh·∫≠p",
      "nh·∫≠n",
      "ti·ªÅn l∆∞∆°ng",
      "th∆∞·ªüng",
      "hoa h·ªìng",
      "ti·ªÅn th∆∞·ªüng",
      "l√£i",
      "c·ªï t·ª©c",
      "b√°n",
      "b√°n ƒë∆∞·ª£c",
      "thu",
      "thu v·ªÅ",
      "nh·∫≠n ƒë∆∞·ª£c",
      "tr√∫ng",
      "ki·∫øm ƒë∆∞·ª£c",
    ];

    // Check if any income keyword is present
    for (const keyword of incomeKeywords) {
      if (lowerText.includes(keyword)) {
        return "IN";
      }
    }

    // Default to expense
    return "OUT";
  }

  /**
   * Parse date from Vietnamese text
   */
  private parseDate(text: string): Date {
    const today = new Date();
    const lowerText = text.toLowerCase();

    // Check for DD/MM/YYYY format
    const dateMatch = text.match(/(\d{1,2})[\/\-](\d{1,2})(?:[\/\-](\d{4}))?/);
    if (dateMatch) {
      const day = parseInt(dateMatch[1]);
      const month = parseInt(dateMatch[2]) - 1;
      const year = dateMatch[3] ? parseInt(dateMatch[3]) : today.getFullYear();
      return new Date(year, month, day);
    }

    // Vietnamese relative dates
    if (lowerText.includes("h√¥m qua")) {
      const yesterday = new Date(today);
      yesterday.setDate(yesterday.getDate() - 1);
      return yesterday;
    }

    if (lowerText.includes("h√¥m kia")) {
      const dayBeforeYesterday = new Date(today);
      dayBeforeYesterday.setDate(dayBeforeYesterday.getDate() - 2);
      return dayBeforeYesterday;
    }

    if (lowerText.includes("tu·∫ßn tr∆∞·ªõc")) {
      const lastWeek = new Date(today);
      lastWeek.setDate(lastWeek.getDate() - 7);
      return lastWeek;
    }

    // N days ago
    const daysAgoMatch = lowerText.match(/(\d+)\s*ng√†y\s*tr∆∞·ªõc/);
    if (daysAgoMatch) {
      const daysAgo = parseInt(daysAgoMatch[1]);
      const date = new Date(today);
      date.setDate(date.getDate() - daysAgo);
      return date;
    }

    return today;
  }

  /**
   * Extract note by removing model-labeled amount span (no regex)
   */
  private extractNote(
    text: string,
    amountResult?: AmountExtractionResult
  ): string {
    if (amountResult?.tokens?.length && amountResult.labels?.length) {
      const kept: string[] = [];
      for (let i = 0; i < amountResult.tokens.length; i++) {
        const label = amountResult.labels[i];
        if (label === "B-AMT" || label === "I-AMT") continue;
        kept.push(amountResult.tokens[i]);
      }
      const note = kept.join(" ").trim();
      return note || "Giao d·ªãch";
    }
    // If no labels (rare), keep raw text.
    return (text || "").trim() || "Giao d·ªãch";
  }

  /**
   * Generate friendly message based on parsed data
   */
  private generateMessage(
    action: string,
    amount: number | null,
    note: string,
    category: Category | undefined,
    date: Date,
    confidence?: number
  ): string {
    if (action === "VIEW_STATS") {
      return "B·∫°n mu·ªën xem th·ªëng k√™ chi ti√™u";
    }

    if (action === "EDIT_TRANSACTION") {
      return "B·∫°n mu·ªën ch·ªânh s·ª≠a giao d·ªãch";
    }

    if (action === "DELETE_TRANSACTION") {
      return "B·∫°n mu·ªën x√≥a giao d·ªãch";
    }

    // CREATE_TRANSACTION
    if (!amount) {
      return "Vui l√≤ng cho bi·∫øt s·ªë ti·ªÅn c·ª• th·ªÉ nh√©! üí∞";
    }

    const formattedAmount = amount.toLocaleString("vi-VN");
    const dateStr = date.toLocaleDateString("vi-VN");
    const categoryName = category?.name || "Ch∆∞a ph√¢n lo·∫°i";
    const emoji = category?.icon || "‚úÖ"; // Use icon from database
    const confidenceStr =
      confidence && confidence < 75 ? ` (${confidence}% ch·∫Øc ch·∫Øn)` : " ‚úì";

    // Detect transaction type from category
    const transactionType = category?.type === "income" ? "thu" : "chi";

    return `ƒê√£ ghi ${transactionType} ${formattedAmount}ƒë cho ${note} v√†o ${dateStr}. Ph√¢n lo·∫°i: ${categoryName}${confidenceStr}.`;
  }

  /**
   * Hybrid amount parser: PhoBERT (ML) + parseAmountVN (regex fallback)
   * Uses PhoBERT for context-aware extraction with confidence scoring
   */
  private async parseAmountHybrid(
    text: string
  ): Promise<AmountExtractionResult> {
    try {
      const phobertResult = await phobertExtractor.extractAmount(text);

      // If model result is low confidence, use regex parser as last resort to avoid null
      if (!phobertResult.amount || phobertResult.confidence < 0.35) {
        const regexAmount = parseAmountVN(text);
        return {
          ...phobertResult,
          amount: phobertResult.amount || regexAmount,
          confidence: phobertResult.amount
            ? phobertResult.confidence
            : regexAmount
            ? 0.25
            : 0,
        };
      }

      return phobertResult;
    } catch (error) {
      console.error("‚ùå Amount extractor failed, using regex fallback:", error);
      const regexAmount = parseAmountVN(text);
      return {
        amount: regexAmount,
        confidence: regexAmount ? 0.2 : 0,
        tokens: [],
        labels: [],
      };
    }
  }

  /**
   * Train model with transaction history (for future use)
   */
  async trainWithHistory(transactions: any[]): Promise<void> {
    // TODO: Implement training logic
    console.log(
      "üéì Training not yet implemented, using rule-based classification"
    );
  }
}

// Export singleton instance
export const tfTransactionParser = new TensorFlowTransactionParser();
